package com.packt.spark.section2

import com.packt.spark._
import org.apache.spark._
import com.github.nscala_time.time.Imports._

object Serialization extends ExampleApp {
  def run() =
    withSparkContext { implicit sc =>
      val violations =
        fullDataset
          .mapPartitions { rows =>
            val parse = Violation.rowParser
            rows.flatMap { row => parse(row) }
          }
          .filter(_.ticket.fine > 5.0)
    }
}
