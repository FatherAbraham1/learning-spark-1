package com.packt.spark.section2

import com.packt.spark._
import org.apache.spark._

object Accumulators extends ExampleApp {
  def run() =
    withSparkContext { implicit sc =>
      val validAcc = sc.accumulator(0)
      val invalidAcc = sc.accumulator(0)

      val violationEntries = 
        sampleDataset
          .flatMap { line =>
            Violation.fromRow(line) match {
              case v @ Some(_) =>
                validAcc += 1
                v
              case None =>
                invalidAcc += 1
                None
            }
          }

      val validCount = validAcc.value
      val invalidCount = invalidAcc.value

      println(s"Valid count: $validCount")
      println(s"Invalid count: $invalidCount")
    }
}
