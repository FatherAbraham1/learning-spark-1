package com.packt.spark.section2

import com.packt.spark._
import org.apache.spark._

object Accumulators extends ExampleApp {
  def run() =
    withSparkContext { implicit sc =>
      val violationEntries = 
        sampleDataset
          .flatMap(Violation.fromRow _)

    val count = violationEntries.count

    println(s"Valid count: ${count}")
  }
}
