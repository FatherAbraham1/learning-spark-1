package com.packt.spark.section2

import com.packt.spark._
import org.apache.spark._

object Accumulators {
  val dataPath = "data/Parking_Violations.csv"

  def getSparkContext(): SparkContext = {
    val conf = 
      new SparkConf()
        .setMaster("local[4]")
        .setAppName("Accumulators")

    new SparkContext(conf)
  }

  def main(args: Array[String]): Unit = {
    val sc = getSparkContext()

    val violationEntries =
      sc.textFile(dataPath)
        .filter(!_.startsWith("Issue"))
        .flatMap(ViolationEntry.parseLine _)

    val count = violationEntries.count

    println(s"Valid count: ${count}")
  }
}
