package com.packt.spark.section2

import com.packt.spark._
import org.apache.spark._

object Accumulators extends ExampleApp {
  def run() =
    withSparkContext { implicit sc =>
      val validAcc = sc.accumulator(0)
      val invalidAcc = sc.accumulator(0)
      val fineAcc = sc.accumulator(0.0)

      val violationEntries = 
        sampleDataset
          .flatMap { line =>
            Violation.fromRow(line) match {
              case e @ Some(violation) =>
                validAcc += 1
                fineAcc += violation.ticket.fine
                e
              case None =>
                invalidAcc += 1
                None
            }
          }

      violationEntries.foreach { x =>  }

      val validCount = validAcc.value
      val invalidCount = invalidAcc.value
      val totalFines = fineAcc.value

      println(s"Valid count: $validCount")
      println(s"Invalid count: $invalidCount")
      println(f"Total fines: $$${totalFines.toLong}%,d")
    }
}
