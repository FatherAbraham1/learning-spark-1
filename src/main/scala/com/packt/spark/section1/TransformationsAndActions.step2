package com.packt.spark.section1

import com.packt.spark._
import org.apache.spark._
import org.apache.spark.rdd._

object TransformationsAndActions extends ExampleApp {
  def run() =
    withSparkContext { implicit sc =>
      val violations: RDD[Violation] = 
        fullDataset
          .flatMap(Violation.fromRow _)
          .filter(_.ticket.fine != 0.0)

      val maxTicket: Ticket =
        violations
          .map(_.ticket)
          .reduce { (ticket1, ticket2) =>
            if(ticket1.fine > ticket2.fine) ticket1
            else ticket2
           }

      val minTicket: Ticket =
        violations
          .map(_.ticket)
          .reduce { (ticket1, ticket2) =>
            if(ticket1.fine < ticket2.fine) ticket1
            else ticket2
           }

      println(s"Maximum Ticket: $maxTicket")
      println(s"Minium Ticket: $minTicket")
    }
}
