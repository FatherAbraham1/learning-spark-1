package com.packt.spark.section1

import com.packt.spark._

import org.apache.spark._

object TransformationsAndActions extends ExampleApp {
  def run() =
    withSparkContext { implicit sc =>
      // Get distinct violations.
      println("Violation Types:")
      val violationTypes =
        violations
          .map(_.ticket.description)
          .distinct
          .foreach { desc => println(s" $desc") }

      val maxFine = 
        violations
          .map(_.ticket.fine)
          .fold(Double.MinValue) { (acc, fine) =>
            math.max(acc, fine)
          }

      // Find max fine.
      val maxFineValue =
        violations.map(_.ticket.fine).max
      val minFineValue =
        violations.map(_.ticket.fine).min

      println(s"Min fine value: $minFineValue")
      println(s"Max fine value: $maxFineValue")

      val maxTicket: Ticket =
        violations
          .map(_.ticket)
          .reduce { (ticket1, ticket2) =>
            if(ticket1.fine > ticket2.fine) ticket1
            else ticket2
           }

      println(s"Maximum Ticket: $maxTicket")

      val (sum, count): (Double, Double) =
        violations
          .map(_.ticket.fine)
          .aggregate( (0.0, 0.0))( 
            { (acc, fine) => (acc._1 + fine, acc._2 + 1) }, 
            { (acc1, acc2) => (acc1._1 + acc2._1, acc1._2 + acc2._2) }
          )

      val mean = sum / count

      println(f"\nSum is $$${sum}%,1.2f\n")
      println(f"\nMean is $$${mean}%,1.2f\n")

      println(s"Max ticket: $maxTicket")

      val bigTicketItems =
        violations
          .filter(_.ticket.fine > 1000.00)
          .map(_.ticket)
          .distinct
          .collect

      println("Big ticket items:")
      for(Ticket(fine, description) <- bigTicketItems) {
        println(s" $fine  $description")
      }
    }
}
